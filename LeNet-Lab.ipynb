{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab Solution\n",
    "![LeNet Architecture](lenet.png)\n",
    "Source: Yan LeCun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uda/.conda/envs/IntroToTensorFlow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
    "\n",
    "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
    "\n",
    "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[N] 6\n",
      "X_train (55000, 28, 28, 1) <class 'tuple'> <class 'numpy.ndarray'> (28, 28, 1)\n",
      "y_train (55000,) <class 'tuple'> <class 'numpy.uint8'> ()\n",
      "squeeze (28, 28) <class 'numpy.ndarray'> (28, 28)\n",
      "X_validation (5000, 28, 28, 1)\n",
      "y_validation (5000,)\n",
      "X_test (10000, 28, 28, 1)\n",
      "y_test (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAC+FJREFUeJzt3WuMFfUZx/HvI5cYwRdsGgGBgqmk\n8RJKEZEEiOBlpbVkxQvCCyQpKb4QA4lvyL5B0xgvEVtMahPaopAIYtSWVYt23TS1xMaAxnApUIix\nK5dADUYwwZDFpy92NsE9//mfOfc5h98nIZzzMDvzH/HHzPzPzHPM3RGRsMsaPQCRPFNARCIUEJEI\nBUQkQgERiVBARCIUEJEIBUQkQgERiRhayQ+b2XxgPTAE+KO7P11keX1sL7nh7lZsGSv3VhMzGwL8\nB7gTOArsApa4+78jP6OASG5kCUglp1gzgCPu/pm7nwdeBToqWJ9I7lQSkHHAFxe9P5rUvsfMVpjZ\nbjPbXcG2RBqikmuQ0OGp4BTK3TcAG0CnWNJ8KjmCHAUmXPR+PHC8suGI5EslAdkFTDaza8xsOLAY\n6KrOsETyoexTLHfvM7OVwHv0T/NudPf9VRuZSA6UPc1b1sZ0DSI5UutpXpGWp4CIRCggIhEKiEiE\nAiISoYCIRCggIhEKiEhERQ9MSXOYNWtWsL5u3bqC2i233BJc9vjx8G1248YV3MDdUnQEEYlQQEQi\nFBCRCAVEJEIX6S1k2rRpwXroYhzg5ptvLqj19fUFl33iiSfKH1gT0xFEJEIBEYlQQEQiFBCRCAVE\nJEKzWE0o7daR7du3B+ttbW3Bem9vb0EtbbbqpZdeyji61lJp8+rPgbPABaDP3adXY1AieVGNI8g8\nd/+yCusRyR1dg4hEVBoQB/5mZh+b2YrQAmpeLc2s0lOsWe5+3MyuArrN7KC7f3DxAmpeLc2sap0V\nzexx4Bt3fy6yjAISMHRo+N+pUaNGBesHDhwI1tNmqw4fPhysr169uqC2Y8eO4LKtqKadFc1shJld\nOfAaaAf2lbs+kTyq5BRrNPBnMxtYzxZ3f7cqoxLJiUq6u38G/KSKYxHJHU3zikQoICIR+n6QHGhv\nbw/W3303fEmX9neWVr/rrruC9Z6engyja136fhCRCikgIhEKiEiEAiISoYCIROiJwjoaMWJEsN7Z\n2VmV9YfurQLNVlVCRxCRCAVEJEIBEYlQQEQiFBCRCM1i1dHKlSuD9Tlz5pS0nu7u7mB98+bNJY9J\n4nQEEYlQQEQiFBCRCAVEJEIBEYko+kShmW0EfgGccvcbk1obsA2YBHwOLHL3r4pu7BJ6ovD+++8v\nqG3ZsiW47JAhQ4L1M2fOBOtXX311sH7u3LmMoxOo3hOFLwPzB9XWAD3uPhnoSd6LtJyiAUlaiZ4e\nVO4ANiWvNwH3VHlcIrlQ7geFo939BIC7n0h68wYlTa2Dja1F8q7mn6SrebU0s3IDctLMxiZHj7HA\nqWoOqhVMmTKloJbWpPrrr78O1hcsWBCs62K8fsqd5u0CliWvlwHhL8cTaXJFA2JmW4F/AT82s6Nm\nthx4GrjTzA4DdybvRVpO0VMsd1+S8ke3V3ksIrmjT9JFIhQQkQg1r67Q3Llzg/Wurq6CWlrbn4MH\nDwbrN9xwQ9njkuLUvFqkQgqISIQCIhKhgIhEKCAiEWr7U6FVq1YF66EZq7QZw/3791d1TFmFHtS6\n7LLS/s1M26e+vr6yxpQ3OoKIRCggIhEKiEiEAiISoYCIRGgWK6Nhw4YF621tbcG6WeFtPq+//npw\n2QcffLCksYwcOTJYnzp1arB+6623BusdHR0FtZtuuim4bGh/AHp7e4P1O+64I1g/cuRIsJ5XOoKI\nRCggIhEKiEiEAiISoYCIRJTbvPpx4FfA/5LFOt39r0U31sRPFM6bNy9Yf//99zOvY/HixcH6zp07\ng/W1a9cG6+3t7cH6xIkTg/W0GahSniYtdR1pjbqXLl2aeZu1Vsvm1QC/cfepya+i4RBpRuU2rxa5\nJFRyDbLSzPaY2UYzG5W2kJmtMLPdZra7gm2JNES5Afk98CNgKnACWJe2oLtvcPfp7j69zG2JNExZ\nAXH3k+5+wd2/A/4AzKjusETyoax7sQY6uydvFwL7qjekfHrooYcqXsfll18erL/wwgvB+r333lvS\n+j/88MNgff369ZnXsWjRomA99JVyMTNnzixp+bwqGpCkefVc4AdmdhRYC8w1s6mA0/8dhQ/XcIwi\nDVNu8+o/1WAsIrmjT9JFIhQQkQgFRCRCTxRmdMUVVwTrafcoHTt2rKD2zjvvBJddsiT8HUVp6967\nd2+wfvvt4e80On/+fLAecu211wbrabNYaWPcunVr5m3mmY4gIhEKiEiEAiISoYCIROgiPaNp06YF\n66U0pD59OvzUQNrtHXPmzAnWz549G6yXcjEOsHDhwoLao48+WtI6QpMRANu2bStpPXmlI4hIhAIi\nEqGAiEQoICIRCohIRNG2P1XdWBO3/bn77ruD9bfeeitYv3DhQkHtvvvuCy7b1dVV/sAymDJlSrD+\n/PPPF9Ruu+224LJpX6nW3d0drKft67fffhusN0K12v6IXLIUEJEIBUQkQgERiVBARCKyNK+eAGwG\nxgDfARvcfb2ZtQHbgEn0dzZZ5O5fFVlX085iDR8+PFhPa149e/bsgtqpU6eCy6Y1o96zZ0+wPmNG\nuA3ZggULgvXly5cH62PGjCmopf3/0NnZGaw/88wzwXozqNYsVh/wmLtfB8wEHjGz64E1QI+7TwZ6\nkvciLSVL8+oT7v5J8voscAAYB3QAm5LFNgH31GqQIo1S0u3uZjYJ+CnwETB6oLuiu58ws6tSfmYF\nsKKyYYo0RuaAmNlI4A1gtbufSXtYfzB33wBsSNbRtNcgcmnKNItlZsPoD8cr7v5mUj5pZmOTPx8L\nhK9ARZpYlt68Rn+r0QPufvHNO13AMuDp5PftNRlhTqQ9rffss88G6+PHjy+oTZo0Kbjsrl27gvW0\n+5+GDRsWrA8dWtoDoocOHSqo7dixI7jsiy++WNK6W0WW/6KzgKXAXjP7NKl10h+M18xsOdALPFCb\nIYo0Tpbm1TuBtAuOcKcykRahT9JFIhQQkQgFRCRCTxTWSGgWK3R/FoT7U0F6w+i0JxCfeuqpjKPr\nF2qCfe7cuZLW0cz0RKFIhRQQkQgFRCRCARGJUEBEIjSLJZcszWKJVEgBEYlQQEQiFBCRCAVEJEIB\nEYlQQEQiFBCRCAVEJEIBEYkoGhAzm2BmfzezA2a238xWJfXHzeyYmX2a/Pp57YcrUl9ZuruPBca6\n+ydmdiXwMf19eBcB37j7c5k3pnuxJEey3IuVpe3PCWCgB+9ZMxtoXi3S8kq6BhnUvBpgpZntMbON\nZjYq5WdWmNluM9td0UhFGiDz7e5J8+p/AE+6+5tmNhr4EnDg1/Sfhv2yyDp0iiW5keUUK1NAkubV\nbwPvDerPO/Dnk4C33f3GIutRQCQ3qvI8SFrz6oHO7omFwL5yBimSZ1lmsWYD/wT20v8dhdDfvHoJ\nMJX+U6zPgYcHvlAnsi4dQSQ3qnaKVS0KiOSJHrkVqZACIhKhgIhEKCAiEQqISIQCIhKhgIhEKCAi\nEQqISERp3zxfuS+B/yavf5C8b3Xaz3yamGWhut5q8r0Nm+129+kN2XgdaT+bm06xRCIUEJGIRgZk\nQwO3XU/azybWsGsQkWagUyyRCAVEJKLuATGz+WZ2yMyOmNmaem+/lpL2R6fMbN9FtTYz6zazw8nv\nwfZIzSTSbbPl9rWuATGzIcDvgJ8B1wNLzOz6eo6hxl4G5g+qrQF63H0y0JO8b3Z9wGPufh0wE3gk\n+XtsuX2t9xFkBnDE3T9z9/PAq0BHncdQM+7+AXB6ULkD2JS83kR/29am5u4n3P2T5PVZYKDbZsvt\na70DMg744qL3R2n9NqajB7q9JL9f1eDxVNWgbpstt6/1Dkioi4TmmZtU0m3zDWC1u59p9Hhqod4B\nOQpMuOj9eOB4ncdQbycHmuwlv59q8HiqIum2+Qbwiru/mZRbbl/rHZBdwGQzu8bMhgOLga46j6He\nuoBlyetlwPYGjqUq0rpt0or7Wu9P0pMv2vktMATY6O5P1nUANWRmW4G59N/6fRJYC/wFeA34IdAL\nPODugy/km0qk2+ZHtNq+6lYTkXT6JF0kQgERiVBARCIUEJEIBUQkQgERiVBARCL+D7WiehJ2zueP\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11047055f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfA70HaxCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1102a19128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11006b8be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "N=1000\n",
    "\n",
    "im=X_train[N].squeeze()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(im, cmap=\"gray\")\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(im)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(X_train[N].squeeze(), cmap=\"gray\")\n",
    "\n",
    "print('y_train[N]',y_train[N])\n",
    "\n",
    "print('X_train',X_train.shape,type(X_train.shape),type(X_train[N]),X_train[N].shape)\n",
    "print('y_train',y_train.shape,type(y_train.shape),type(y_train[N]),y_train[N].shape)\n",
    "print('squeeze',im.shape,type(im),im.shape)\n",
    "\n",
    "print('X_validation',X_validation.shape)\n",
    "print('y_validation',y_validation.shape)\n",
    "print('X_test',X_test.shape)\n",
    "print('y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1100532e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADqtJREFUeJzt3X2MVfWdx/HPl2FgFB+KdVEWaLEs\n6+raFdsptoE2NAbjA1nALqY0tWy26bS7ZaMb/9B105Vs3I02PrRJW+lQWTFBrdvWBROzLZ0060OV\nOhBStdRKXGoRCuq0MgLyMPPdP+bQTHHO717uPfeeO/N9vxIy957vefh65cO5d37nnp+5uwDEM67s\nBgCUg/ADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwhqfDMPNsEmeocmNfOQQCjv6ICO+GGrZt26\nwm9mV0j6uqQ2Sd9x99tT63doki61y+o5JICEzd5T9bo1v+03szZJ35R0paQLJS03swtr3R+A5qrn\nM/9cSTvc/RV3PyLpYUmLi2kLQKPVE/5pkn4z7PmubNkfMbMuM+s1s96jOlzH4QAUqZ7wj/RLhXd9\nP9jdu92909072zWxjsMBKFI94d8lacaw59Ml7a6vHQDNUk/4n5M028zOM7MJkj4taWMxbQFotJqH\n+tz9mJmtlPRDDQ31rXX3FwvrDEBD1TXO7+6PS3q8oF4ANBGX9wJBEX4gKMIPBEX4gaAIPxAU4QeC\nIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFRTb92NeA5f/ZHc2of/bUty27umbk3Wew61JetfnfXB\nZD06zvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/KjLwCc/lKynxvJvP/e55LYHBweS9eu7b0jW\np+mnyXp0nPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKi6xvnNbKekfkkDko65e2cRTaF1pL6PL0lf\n+8Y3kvUPTmjPrT128Mzktv+6+nPJ+rS7GMevRxEX+XzS3d8oYD8Amoi3/UBQ9YbfJf3IzLaYWVcR\nDQFojnrf9s9z991mNkXSJjP7pbs/MXyF7B+FLknq0Kl1Hg5AUeo687v77uznPkmPSpo7wjrd7t7p\n7p3tmljP4QAUqObwm9kkMzv9+GNJl0t6oajGADRWPW/7z5H0qJkd38+D7v4/hXQFoOFqDr+7vyLp\n4gJ7QQNY+4Rkve3cKcn6HXWM40vS/fv/NLe25rYlyW2nrmccv5EY6gOCIvxAUIQfCIrwA0ERfiAo\nwg8Exa27x7j916Rvrf3k3d9K1gcr/BU5pvTttf/zK4tza2d+79nktmgszvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EBTj/GNA23vyb4F9/j+92NBjX3Lv9cn6jO/xtdxWxZkfCIrwA0ERfiAowg8ERfiB\noAg/EBThB4JinH8M2HHThbm1DTPSt96WLFldtuOqZH3m6peS9fS3/VEmzvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EFTFcX4zWytpkaR97n5RtuwsSd+VNFPSTknXuvvvGtdmbG9+4WPJ+tbr7klU01No\n/+roO8n64UUHk/XB/v5kHa2rmjP//ZKuOGHZzZJ63H22pJ7sOYBRpGL43f0JSX0nLF4saV32eJ2k\nJQX3BaDBav3Mf46775Gk7OeU4loC0AwNv7bfzLokdUlSh05t9OEAVKnWM/9eM5sqSdnPfXkrunu3\nu3e6e2e7JtZ4OABFqzX8GyWtyB6vkLShmHYANEvF8JvZQ5KekXS+me0ys89Lul3SQjN7WdLC7DmA\nUaTiZ353X55TuqzgXpCj7yJP1k+xCbm1SuP4X/rHG5L1jv6fJesYvbjCDwiK8ANBEX4gKMIPBEX4\ngaAIPxAUt+5uAQeXXpqs9yy5M1kf1Cm5tR8fuCC5bcdjDOVFxZkfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4JinL8FtP393mR9+vj8cXxJGtRgbm39rz+S3PZM7UjWG8nGV/jr19ZW3wEG878K7UeP1Lfv\nMYAzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/E9jE9ExFs854I1kfJ0vW5237TG5t8tUvJ7et\npG3y5GT9wPzZyfruj+eP1V+z8JnktrdN2ZysV3pdHjt4Rm7t28v+Ornt4LZfJOtjAWd+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiq4ji/ma2VtEjSPne/KFu2StIXJL2erXaLuz/eqCZHu7cXzUnWV8/4\nVrKe/239IQMbzs6tjf/A0eS2L932nmT9PzofTdaXTvpxsp4aix9Ueurxel196lu5tVtXpY997pKi\nu2k91Zz575d0xQjL73H3Odkfgg+MMhXD7+5PSOprQi8Amqiez/wrzeznZrbWzNLXgAJoObWG/15J\nsyTNkbRH0l15K5pZl5n1mlnvUR2u8XAAilZT+N19r7sPuPugpDWS5ibW7Xb3TnfvbFf6Cy4Amqem\n8JvZ1GFPl0p6oZh2ADRLNUN9D0laIOlsM9sl6VZJC8xsjiSXtFPSFxvYI4AGqBh+d18+wuL7GtDL\nmNW3/EBD9z/QkT+W3vfN9L3vt/9Vff8rV742P1nfsiZ9jUPK+KWvJ+tPX/xIzfu+8S82JevrNb3m\nfY8WXOEHBEX4gaAIPxAU4QeCIvxAUIQfCIpbdzfBaaekL2uudAvqTYfSU3RP+69Xcmt2TXrflY59\nZ9/5yfqrn0h/Nfa976Rvz53yf7M+ll7h4nQ59d+26od/k9x2tp5N73wM4MwPBEX4gaAIPxAU4QeC\nIvxAUIQfCIrwA0Exzt8EK2f9JFmvdAvr1a8tSNaP7fltbq1tafr2ivOu+odkfeJb6RuHd7zzs2Q9\n5c3Pp8fx713WXfO+JannUP6do/7s4UN17Xss4MwPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZe2On\nSR7uDDvLL7XLmna8VvHWZz+arD99R3qK7sN+LFlf8C/X59Ymr6v9+/RFGJyff+vu997xanLb9TPT\n038f8iPJ+rUvX5Nb80X503dL0uCBxt5uvVE2e4/2e1/6Jg0ZzvxAUIQfCIrwA0ERfiAowg8ERfiB\noAg/EFTFcX4zmyHpAUnnShqU1O3uXzezsyR9V9JMSTslXevuv0vtK+o4/7iOjmR9+v+mp9FePf3J\nZP3ZxLQAqz73d8ltxz21LVk/enlnsr5zUbr3tVevya19vCN9/UKl+xz85QMrk/Xz/rncaxzKUPQ4\n/zFJN7r7BZI+KunLZnahpJsl9bj7bEk92XMAo0TF8Lv7Hnffmj3ul7Rd0jRJiyWty1ZbJ2lJo5oE\nULyT+sxvZjMlXSJps6Rz3H2PNPQPhKQpRTcHoHGqDr+ZnSbp+5JucPf9J7Fdl5n1mlnvUaXnrAPQ\nPFWF38zaNRT89e7+g2zxXjObmtWnSto30rbu3u3une7e2a78GyoCaK6K4Tczk3SfpO3ufvew0kZJ\nK7LHKyRtKL49AI1SzVDffElPSnpeQ0N9knSLhj73PyLpfZJelbTM3ftS+4o61FfJ769L38L6xq88\nmKx/alL+COvbnv6odXBwIFk/fVz67u6n2IRkPWXNWzOS9Tt+emWyfsFN+VOTS9LAm8m/jmPSyQz1\nVbxvv7s/JeVOdE6SgVGKK/yAoAg/EBThB4Ii/EBQhB8IivADQXHr7lGg7c9nJeu/vSz/axXjF72R\n3PbpOQ8n6wtf/FSyPu7Os5P1lInPvJSsD/b317zvqLh1N4CKCD8QFOEHgiL8QFCEHwiK8ANBEX4g\nKMb5gTGEcX4AFRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC\nIvxAUBXDb2YzzOwnZrbdzF40s+uz5avM7DUz25b9uarx7QIoyvgq1jkm6UZ332pmp0vaYmabsto9\n7n5n49oD0CgVw+/ueyTtyR73m9l2SdMa3RiAxjqpz/xmNlPSJZI2Z4tWmtnPzWytmU3O2abLzHrN\nrPeoDtfVLIDiVB1+MztN0vcl3eDu+yXdK2mWpDkaemdw10jbuXu3u3e6e2e7JhbQMoAiVBV+M2vX\nUPDXu/sPJMnd97r7gLsPSlojaW7j2gRQtGp+22+S7pO03d3vHrZ86rDVlkp6ofj2ADRKNb/tnyfp\nOknPm9m2bNktkpab2RxJLmmnpC82pEMADVHNb/ufkjTSfcAfL74dAM3CFX5AUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgzN2bdzCz1yX9etiisyW90bQGTk6r\n9taqfUn0Vqsie3u/u/9JNSs2NfzvOrhZr7t3ltZAQqv21qp9SfRWq7J6420/EBThB4IqO/zdJR8/\npVV7a9W+JHqrVSm9lfqZH0B5yj7zAyhJKeE3syvM7CUz22FmN5fRQx4z22lmz2czD/eW3MtaM9tn\nZi8MW3aWmW0ys5eznyNOk1ZSby0xc3NiZulSX7tWm/G66W/7zaxN0q8kLZS0S9Jzkpa7+y+a2kgO\nM9spqdPdSx8TNrNPSHpb0gPuflG27KuS+tz99uwfzsnuflOL9LZK0ttlz9ycTSgzdfjM0pKWSPpb\nlfjaJfq6ViW8bmWc+edK2uHur7j7EUkPS1pcQh8tz92fkNR3wuLFktZlj9dp6C9P0+X01hLcfY+7\nb80e90s6PrN0qa9doq9SlBH+aZJ+M+z5LrXWlN8u6UdmtsXMuspuZgTnZNOmH58+fUrJ/Zyo4szN\nzXTCzNIt89rVMuN10coI/0iz/7TSkMM8d/+QpCslfTl7e4vqVDVzc7OMMLN0S6h1xuuilRH+XZJm\nDHs+XdLuEvoYkbvvzn7uk/SoWm/24b3HJ0nNfu4ruZ8/aKWZm0eaWVot8Nq10ozXZYT/OUmzzew8\nM5sg6dOSNpbQx7uY2aTsFzEys0mSLlfrzT68UdKK7PEKSRtK7OWPtMrMzXkzS6vk167VZrwu5SKf\nbCjja5LaJK11939vehMjMLMPaOhsLw1NYvpgmb2Z2UOSFmjoW197Jd0q6b8lPSLpfZJelbTM3Zv+\ni7ec3hZo6K3rH2ZuPv4Zu8m9zZf0pKTnJQ1mi2/R0Ofr0l67RF/LVcLrxhV+QFBc4QcERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IKj/B7PeLkBHgOKXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11046eada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngvp/czL6XIjMdhoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f110057a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train[N].shape)\n",
    "\n",
    "im=X_train[N].squeeze()\n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "\n",
    "\n",
    "print(X_validation[N].shape)\n",
    "\n",
    "im=X_validation[N].squeeze()\n",
    "plt.figure()\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n",
      "X_train (55000, 32, 32, 1)\n",
      "X_validation (5000, 32, 32, 1)\n",
      "X_test (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#　パディングにより入力データを32x32に修正する （重要）\n",
    "\n",
    "# Pad images with 0s\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))\n",
    "print('X_train',X_train .shape)\n",
    "print('X_validation',X_validation .shape)\n",
    "print('X_test',X_test .shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "View a sample from the dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2yBWbINYsQ1ixTaIFdsg/wM9cx3yWR6hTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1102d55860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11004c8ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "#①ネットワークを構築する\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6. \n",
    "    # 5x5のフィルタを適用すると幅高さ32x32→幅高さ28x28となる\n",
    "    # 加えて入力深度が１，出力深度が6なので　shape=(5, 5, 1, 6)を適用する\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))  \n",
    "    #出力深度が6なのでバイアスも６セット用意\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    #出力結果にreluを適用する\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    #　maxプーリングを使ってサイズを縮小する\n",
    "    #　入力が[index,幅,高さ,深度]なので第0th,3thは１　1th,2thにカーネルとストライドサイズを設定\n",
    "    #　ksize=[1, w, h, 1]　strides=[1, hstride, vstride, 1]\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Input = 14x14x6.　Output = 10x10x16.\n",
    "    #　フィルタサイズが5x5　入力深度が6　出力深度が16\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    #　5ｘ5ｘ16＝400　1次元に変換\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    #　tf.Variable(tf.Sessionのための準備)を実行\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ひな形を用意する\n",
    "\n",
    "#　32ｘ32ｘ1の画像を用意（index=None :大きさを指定しない）\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "\n",
    "#y(int32型ラベルデータ)を10パターン分　one_hotデータ(結果)として用意\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#トレーニング内容を定義する\n",
    "\n",
    "rate = 0.001\n",
    "#用意したLeNet関数に入力x（32x32x1型画像を適用）\n",
    "# ※※※ xはplaceholderで定義　且つ　section内の「辞書」で入力実行※※\n",
    "logits = LeNet(x)\n",
    "#結果をソフトマックス・クロスエントロピーに適用\n",
    "########## \n",
    "#等価処理は　　　　　　　 y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "##########  cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# ※※※ ｙone_hot_yはplaceholderで定義したyより生成　且つ　section内の「辞書」で入力実行※※\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "#総和平均で得点を計算\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#Adam法による最急降下を選択　\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "#他最急降下法の適用例：　optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "#Adam法で評価\n",
    "training_operation = optimizer.minimize(loss_operation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#スコア評価方法を定義する\n",
    "\n",
    "#tf.argmaxの引数\n",
    "#tf.argmax（A,B)　　Aが真のデータ、Bが評価されるデータ\n",
    "#行列についてはdimensionに0を指定すると、行成分についての最大値をもつ要素（列成分）の添字を返却します。\n",
    "#一方dimensionに1を指定すると、列成分についての最小値を持つ要素（行成分）の添字を返却します。\n",
    "\n",
    "#tf.equal：ベクトルが一致しているか否か　True or False　（LeNet結果とOne_Hot値）\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "#総和平均で得点を計算 →　logitsとone_hotの件数分（例：55000件)のTRUE,FALSEが戻る　全部Trueならtf.reduce_meanは100％一致と出力する\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "tf_argmax=[[tf.argmax(logits, 1)] , [tf.argmax(one_hot_y, 1)]]\n",
    "\n",
    "####################################################\n",
    "flg= tf.cast(correct_prediction, tf.int32)\n",
    "accuracy_operation_custom=    tf.cast(pow(-1,flg+1) ,tf.int32) *   tf.cast(tf.argmax(logits, 1) ,tf.int32) \n",
    "#######################################################\n",
    "\n",
    "#accuracy_operation_custom = correct_prediction\n",
    "\n",
    "\n",
    "#Tensorflowの学習パラーメータのsave, restoreにはtf.train.Saverを使用\n",
    "#　　→　tf.train.Saver()の引数を指定しない場合は全ての変数が保存\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    #変数の初期化　global_variables_initializer\n",
    "    #セッション中身を元の状態に戻す（再リセット）\n",
    "    sess = tf.get_default_session()\n",
    "    \n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "##############以降　追加のカスタムファンクション################################################\n",
    "def evaluatecustom(X_data, y_data):\n",
    "    sess = tf.get_default_session()\n",
    "    return  sess.run(accuracy_operation_custom  , feed_dict={x:X_data, y:y_data})\n",
    "\n",
    "def show_debug(X_data, y_data):\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    print(sess.run(cross_entropy  , feed_dict={x:X_data, y:y_data}) )\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    z_one_hot=sess.run(one_hot_y  , feed_dict={x:X_data, y:y_data}) \n",
    "    print('one_hot_y',z_one_hot,np.max(z_one_hot))\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    zlogits=sess.run(logits  , feed_dict={x:X_data, y:y_data})\n",
    "    print('logits',zlogits,np.max(zlogits) )\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    zargmax=sess.run(tf_argmax  , feed_dict={x:X_data, y:y_data}) \n",
    "    print(zargmax)\n",
    "    print('tf_argmax:logits',zargmax[0])\n",
    "    print('tf_argmax:one_hot',zargmax[1])\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    z_prediction=sess.run(correct_prediction  , feed_dict={x:X_data, y:y_data}) \n",
    "    print('correct_prediction',z_prediction)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith tf.Session() as sess:\\n    sess.run(tf.global_variables_initializer())\\n    num_examples = len(X_train)\\n    \\n    print(\"Training...\")\\n    print()\\n    ##\\u3000EPOCHS=10（パターンが数字0〜9の10種類\\u3000→\\u30001データずつ確認）\\n    for i in range(EPOCHS):\\n        #順序依存の誤教示を排除するためシャッフルする\\n        X_train, y_train = shuffle(X_train, y_train)\\n        #55000点データをBATCH_SIZE分ずつ処理\\n        for offset in range(0, num_examples, BATCH_SIZE):\\n            end = offset + BATCH_SIZE\\n            \\n            #batchはX_train、Y_trainの抜き出し部分（実入力データ）\\n            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\\n            \\n            #先に定義したtraining_operation（Adam法）で入力データ[X_train,Y_train]を評価値に変換する\\n            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\\n            \\n            \\n        #評価データX_validation, y_validation\\u3000でevaluateの実行    \\n        validation_accuracy = evaluate(X_validation, y_validation)\\n        print(\"EPOCH {} ...\".format(i+1))\\n        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\\n        print()\\n        \\n    saver.save(sess, \\'./lenet\\')\\n    print(\"Model saved\")\\n  ##  tf.train.Saver.last_checkpoints\\n\\n\\n\\n#saver.save(sess, \\'./lenet\\')実行により\\n#①lenet.data-00000-of-00001②lenet.index③lenet.meta④checkpointの計４ファイルが記録される\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train訓練データ,Y_trainラベルデータを用いてモデルを作成\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    ##　EPOCHS=10（パターンが数字0〜9の10種類　→　1データずつ確認）\n",
    "    for i in range(EPOCHS):\n",
    "        #順序依存の誤教示を排除するためシャッフルする\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        #55000点データをBATCH_SIZE分ずつ処理\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            \n",
    "            #batchはX_train、Y_trainの抜き出し部分（実入力データ）\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            \n",
    "            #先に定義したtraining_operation（Adam法）で入力データ[X_train,Y_train]を評価値に変換する\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "            \n",
    "        #評価データX_validation, y_validation　でevaluateの実行    \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "  ##  tf.train.Saver.last_checkpoints\n",
    "\n",
    "\n",
    "\n",
    "#saver.save(sess, './lenet')実行により\n",
    "#①lenet.data-00000-of-00001②lenet.index③lenet.meta④checkpointの計４ファイルが記録される\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.988\n"
     ]
    }
   ],
   "source": [
    "#手法①　checkpointファイルで指定された定義モデルを restoreでファイルからリロードする！\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "   \n",
    "    #X_test, y_testに対してevaluateの実行    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.988\n"
     ]
    }
   ],
   "source": [
    "#手法②　先に記録した定義モデルをrestoreでファイルからリロードする！\n",
    "import tensorflow as tf\n",
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')\n",
    "\n",
    "    #X_test, y_testに対してevaluateの実行    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./lenet\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.train.latest_checkpoint('.'))\n",
    "#結果はsaver.saveで指示した　'./lenet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "lbl [9]\n",
      "[  9.67932574e-05]\n",
      "one_hot_y [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]] 1.0\n",
      "logits [[ -5.4977951  -10.64902973  -3.14745641   3.99339271  -1.13802612\n",
      "   -4.8124485  -16.14008713   0.86480272   1.73923862  13.3809948 ]] 13.381\n",
      "[[array([9])], [array([9])]]\n",
      "tf_argmax:logits [array([9])]\n",
      "tf_argmax:one_hot [array([9])]\n",
      "correct_prediction [ True]\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "lbl [7]\n",
      "[ 0.0015359]\n",
      "one_hot_y [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]] 1.0\n",
      "logits [[-10.65982533   0.99044192   5.2156744    0.99247092  -5.79296827\n",
      "   -9.20542049 -20.10249138  11.72268391  -4.14052629  -3.17024112]] 11.7227\n",
      "[[array([7])], [array([7])]]\n",
      "tf_argmax:logits [array([7])]\n",
      "tf_argmax:one_hot [array([7])]\n",
      "correct_prediction [ True]\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "lbl [4]\n",
      "[ 0.99642766]\n",
      "one_hot_y [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]] 1.0\n",
      "logits [[-6.20117664 -4.78960323 -3.9623642  -6.55166817  7.86302614  0.40245712\n",
      "  -5.06035662 -4.36862326  0.71889073  8.39788342]] 8.39788\n",
      "[[array([9])], [array([4])]]\n",
      "tf_argmax:logits [array([9])]\n",
      "tf_argmax:one_hot [array([4])]\n",
      "correct_prediction [False]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    OK=113\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')    \n",
    "    \n",
    "    X_try = np.array( [X_test[OK]])\n",
    "    y_try = np.array( [y_test[OK]])\n",
    "    print('lbl',y_try)\n",
    "    show_debug(X_try,y_try)\n",
    "    \n",
    "    OK=114 \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')    \n",
    "    X_try = np.array( [X_test[OK]])\n",
    "    y_try = np.array( [y_test[OK]])\n",
    "    print('lbl',y_try)\n",
    "    show_debug(X_try,y_try)\n",
    "\n",
    "    NG=115\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')    \n",
    "    X_try = np.array( [X_test[NG]])\n",
    "    y_try = np.array( [y_test[NG]])\n",
    "    print('lbl',y_try)\n",
    "    show_debug(X_try,y_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "i 115\n",
      "(10000, 32, 32, 1) <class 'numpy.ndarray'>\n",
      "(1, 32, 32, 1)\n",
      "4\n",
      "[-9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv1Qowy8VyvBLhTL8UqH+D7Eh9jHVUIizAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10f730e668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "#先に記録した定義モデルをrestoreでファイルからリロードする！\n",
    "    saver.restore(sess, './lenet')\n",
    "\n",
    "    for i in range(X_test.shape[0]) : \n",
    "        X_try = np.array( [X_test[i]])\n",
    "        y_try = np.array( [y_test[i]])\n",
    "\n",
    "        n=( evaluatecustom(X_try, y_try) )\n",
    "        #print(n)\n",
    "        if(n<0):\n",
    "            print('i',i)\n",
    "            print(X_test.shape,type(X_test))\n",
    "            print(X_try.shape)\n",
    "\n",
    "            print(y_test[i])\n",
    "            print(n)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(X_try.squeeze())\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
