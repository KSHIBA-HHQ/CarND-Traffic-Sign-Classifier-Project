{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab Solution\n",
    "![LeNet Architecture](lenet.png)\n",
    "Source: Yan LeCun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshiba/conda/envs/IntroToTensorFlow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
    "\n",
    "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
    "\n",
    "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[N] 6\n",
      "X_train (55000, 28, 28, 1) <class 'tuple'> <class 'numpy.ndarray'> (28, 28, 1)\n",
      "y_train (55000,) <class 'tuple'> <class 'numpy.uint8'> ()\n",
      "squeeze (28, 28) <class 'numpy.ndarray'> (28, 28)\n",
      "X_validation (5000, 28, 28, 1)\n",
      "y_validation (5000,)\n",
      "X_test (10000, 28, 28, 1)\n",
      "y_test (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff33a108cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfA70HaxCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3384805c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3360b7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "N=1000\n",
    "\n",
    "im=X_train[N].squeeze()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(im, cmap=\"gray\")\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(im)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(X_train[N].squeeze(), cmap=\"gray\")\n",
    "\n",
    "print('y_train[N]',y_train[N])\n",
    "\n",
    "print('X_train',X_train.shape,type(X_train.shape),type(X_train[N]),X_train[N].shape)\n",
    "print('y_train',y_train.shape,type(y_train.shape),type(y_train[N]),y_train[N].shape)\n",
    "print('squeeze',im.shape,type(im),im.shape)\n",
    "\n",
    "print('X_validation',X_validation.shape)\n",
    "print('y_validation',y_validation.shape)\n",
    "print('X_test',X_test.shape)\n",
    "print('y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff335f272e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBThB4Ii/EBQhB8IivADQRF+IKj/B7PeLkBHgOKXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff33a1085f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngvp/czL6XIjMdhoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff335f66940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train[N].shape)\n",
    "\n",
    "im=X_train[N].squeeze()\n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "\n",
    "\n",
    "print(X_validation[N].shape)\n",
    "\n",
    "im=X_validation[N].squeeze()\n",
    "plt.figure()\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n",
      "X_train (55000, 32, 32, 1)\n",
      "X_validation (5000, 32, 32, 1)\n",
      "X_test (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#　パディングにより入力データを32x32に修正する （重要）\n",
    "\n",
    "# Pad images with 0s\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))\n",
    "print('X_train',X_train .shape)\n",
    "print('X_validation',X_validation .shape)\n",
    "print('X_test',X_test .shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "View a sample from the dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff335f6fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsWIbxIptECu2QazYBvkf4jARKHlJRFgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff335f4ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "#①ネットワークを構築する\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6. \n",
    "    # 5x5のフィルタを適用すると幅高さ32x32→幅高さ28x28となる\n",
    "    # 加えて入力深度が１，出力深度が6なので　shape=(5, 5, 1, 6)を適用する\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))  \n",
    "    #出力深度が6なのでバイアスも６セット用意\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    #出力結果にreluを適用する\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    #　maxプーリングを使ってサイズを縮小する\n",
    "    #　入力が[index,幅,高さ,深度]なので第0th,3thは１　1th,2thにカーネルとストライドサイズを設定\n",
    "    #　ksize=[1, w, h, 1]　strides=[1, hstride, vstride, 1]\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Input = 14x14x6.　Output = 10x10x16.\n",
    "    #　フィルタサイズが5x5　入力深度が6　出力深度が16\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    #　5ｘ5ｘ16＝400　1次元に変換\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    #　tf.Variable(tf.Sessionのための準備)を実行\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ひな形を用意する\n",
    "\n",
    "#　32ｘ32ｘ1の画像を用意（index=None :大きさを指定しない）\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "\n",
    "#y(int32型ラベルデータ)を10パターン分　one_hotデータ(結果)として用意\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#トレーニング内容を定義する\n",
    "\n",
    "rate = 0.001\n",
    "#用意したLeNet関数に入力x（32x32x1型画像を適用）\n",
    "# ※※※ xはplaceholderで定義　且つ　section内の「辞書」で入力実行※※\n",
    "logits = LeNet(x)\n",
    "#結果をソフトマックス・クロスエントロピーに適用\n",
    "########## \n",
    "#等価処理は　　　　　　　 y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "##########  cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# ※※※ ｙone_hot_yはplaceholderで定義したyより生成　且つ　section内の「辞書」で入力実行※※\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "#総和平均で得点を計算\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#Adam法による最急降下を選択　\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "#他最急降下法の適用例：　optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "#Adam法で評価\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "#　「training_operation」が　本プロジェクトの骨子・核である「モデル生成および鍛錬」の為の処理である\n",
    "#　　最急降下法に与える学習レートを調整しながら、とにかくtraining_operationを繰り返すほどモデル精度が向上する\n",
    "#　　（ただし、過学習には注意　)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#スコア評価方法を定義する\n",
    "\n",
    "#tf.argmaxの引数\n",
    "#tf.argmax（A,B)　　Aが真のデータ、Bが評価されるデータ\n",
    "#行列についてはdimensionに0を指定すると、行成分についての最大値をもつ要素（列成分）の添字を返却します。\n",
    "#一方dimensionに1を指定すると、列成分についての最小値を持つ要素（行成分）の添字を返却します。\n",
    "\n",
    "#tf.equal：ベクトルが一致しているか否か　True or False　（LeNet結果とOne_Hot値）\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "#総和平均で得点を計算 →　logitsとone_hotの件数分（例：55000件)のTRUE,FALSEが戻る　全部Trueならtf.reduce_meanは100％一致と出力する\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "tf_argmax=[[tf.argmax(logits, 1)] , [tf.argmax(one_hot_y, 1)]]\n",
    "\n",
    "####################################################\n",
    "flg= tf.cast(correct_prediction, tf.int32)\n",
    "accuracy_operation_custom=    tf.cast(pow(-1,flg+1) ,tf.int32) *   tf.cast(tf.argmax(logits, 1) ,tf.int32) \n",
    "#######################################################\n",
    "\n",
    "#accuracy_operation_custom = correct_prediction\n",
    "\n",
    "\n",
    "#Tensorflowの学習パラーメータのsave, restoreにはtf.train.Saverを使用\n",
    "#　　→　tf.train.Saver()の引数を指定しない場合は全ての変数が保存\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    #変数の初期化　global_variables_initializer\n",
    "    #セッション中身を元の状態に戻す（再リセット）\n",
    "    sess = tf.get_default_session()\n",
    "    \n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "##############以降　追加のカスタムファンクション################################################\n",
    "def evaluatecustom(X_data, y_data):\n",
    "    sess = tf.get_default_session()\n",
    "    return  sess.run(accuracy_operation_custom  , feed_dict={x:X_data, y:y_data})\n",
    "\n",
    "def show_debug(X_data, y_data):\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    print(sess.run(cross_entropy  , feed_dict={x:X_data, y:y_data}) )\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    z_one_hot=sess.run(one_hot_y  , feed_dict={x:X_data, y:y_data}) \n",
    "    print('one_hot_y',z_one_hot,np.max(z_one_hot))\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    zlogits=sess.run(logits  , feed_dict={x:X_data, y:y_data})\n",
    "    print('logits',zlogits,np.max(zlogits) )\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    zargmax=sess.run(tf_argmax  , feed_dict={x:X_data, y:y_data}) \n",
    "    print(zargmax)\n",
    "    print('tf_argmax:logits',zargmax[0])\n",
    "    print('tf_argmax:one_hot',zargmax[1])\n",
    "    \n",
    "    sess = tf.get_default_session()\n",
    "    z_prediction=sess.run(correct_prediction  , feed_dict={x:X_data, y:y_data}) \n",
    "    print('correct_prediction',z_prediction)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "EPOCH 2 ...\n",
      "EPOCH 3 ...\n",
      "EPOCH 4 ...\n",
      "EPOCH 5 ...\n",
      "EPOCH 6 ...\n",
      "EPOCH 7 ...\n",
      "EPOCH 8 ...\n",
      "EPOCH 9 ...\n",
      "EPOCH 10 ...\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "#X_train訓練データ,Y_trainラベルデータを用いてモデルを作成\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    ##　EPOCHS=10（パターンが数字0〜9の10種類　→　1データずつ確認）\n",
    "    for i in range(EPOCHS):\n",
    "    \n",
    "        #順序依存の誤教示を排除するためシャッフルする\n",
    "        #　→　シャッフルにより　少数第２位水準で　実行のたびにモデル精度が変化する（シャッフル不要かも？）\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        \n",
    "        #55000点データをBATCH_SIZE分ずつ処理\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            \n",
    "            #batchはX_train、Y_trainの抜き出し部分（実入力データ）\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            \n",
    "            #先に定義したtraining_operation（Adam法）で入力データ[X_train,Y_train]を評価値に変換する\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "    \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "\n",
    "    \"\"\" # evaluate は単なるデバッグのためだけの評価処理\n",
    "        #　　従ってevaluate は生成モデルの精度と全く無関係　\n",
    "    　　#  　評価データX_validation, y_validation　は評価目的だけの変数(無駄)\n",
    "        #　　　　　　→X_test, y_test だけあれば動作評価できる\n",
    "        \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    \"\"\"        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "  ##  tf.train.Saver.last_checkpoints\n",
    "\n",
    "\n",
    "\n",
    "#saver.save(sess, './lenet')実行により\n",
    "#①lenet.data-00000-of-00001②lenet.index③lenet.meta④checkpointの計４ファイルが記録される\n",
    "\n",
    "#　saver.save(sess, './lenet')で保存されたモデルデータがあれば、Train the Modelは、以降　再実行の必要ない！！\n",
    "#　→　jupyterで　本ステップは省略・次項へ　スキップ可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.989\n"
     ]
    }
   ],
   "source": [
    "#手法①　checkpointファイルで指定された定義モデルを restoreでファイルからリロードする！\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "   \n",
    "    #X_test, y_testに対してevaluateの実行    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.989\n"
     ]
    }
   ],
   "source": [
    "#手法②　先に記録した定義モデルをrestoreでファイルからリロードする！\n",
    "import tensorflow as tf\n",
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')\n",
    "\n",
    "    #X_test, y_testに対してevaluateの実行    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    \n",
    "##***ディフォルトの精度******　    \n",
    "##INFO:tensorflow:Restoring parameters from ./lenet\n",
    "##Test Accuracy = 0.988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./lenet\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.train.latest_checkpoint('.'))\n",
    "#結果はsaver.saveで指示した　'./lenet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "lbl [9]\n",
      "[  9.89432192e-06]\n",
      "one_hot_y [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]] 1.0\n",
      "logits [[ -4.25255442 -10.8338089   -4.86173916   4.43279505  -2.75371194\n",
      "   -3.87017369 -10.27547646  -0.88582116  -0.31856254  15.97699738]] 15.977\n",
      "[[array([9])], [array([9])]]\n",
      "tf_argmax:logits [array([9])]\n",
      "tf_argmax:one_hot [array([9])]\n",
      "correct_prediction [ True]\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "lbl [7]\n",
      "[  3.26628106e-05]\n",
      "one_hot_y [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]] 1.0\n",
      "logits [[ -8.31151867  -4.20266104   2.84135938   1.75138283  -2.63236737\n",
      "   -9.00168991 -16.2844696   13.4738903   -3.4603281   -1.60532534]] 13.4739\n",
      "[[array([7])], [array([7])]]\n",
      "tf_argmax:logits [array([7])]\n",
      "tf_argmax:one_hot [array([7])]\n",
      "correct_prediction [ True]\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "lbl [4]\n",
      "[ 0.06185926]\n",
      "one_hot_y [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]] 1.0\n",
      "logits [[-6.44137716 -8.89743614 -3.40324402 -5.98299265  8.86319447 -2.31431389\n",
      "  -2.59111547 -9.86291599  1.94911337  6.09521961]] 8.86319\n",
      "[[array([4])], [array([4])]]\n",
      "tf_argmax:logits [array([4])]\n",
      "tf_argmax:one_hot [array([4])]\n",
      "correct_prediction [ True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    OK=113\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')    \n",
    "    \n",
    "    X_try = np.array( [X_test[OK]])\n",
    "    y_try = np.array( [y_test[OK]])\n",
    "    print('lbl',y_try)\n",
    "    show_debug(X_try,y_try)\n",
    "    \n",
    "    OK=114 \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')    \n",
    "    X_try = np.array( [X_test[OK]])\n",
    "    y_try = np.array( [y_test[OK]])\n",
    "    print('lbl',y_try)\n",
    "    show_debug(X_try,y_try)\n",
    "\n",
    "    NG=115\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, './lenet')    \n",
    "    X_try = np.array( [X_test[NG]])\n",
    "    y_try = np.array( [y_test[NG]])\n",
    "    print('lbl',y_try)\n",
    "    show_debug(X_try,y_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "i 18\n",
      "(10000, 32, 32, 1) <class 'numpy.ndarray'>\n",
      "(1, 32, 32, 1)\n",
      "3\n",
      "[-8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ItESuEXiZTCLxIphV8kUv8HAeyFKYPTjOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff335f4b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "#先に記録した定義モデルをrestoreでファイルからリロードする！\n",
    "    saver.restore(sess, './lenet')\n",
    "\n",
    "    for i in range(X_test.shape[0]) : \n",
    "        X_try = np.array( [X_test[i]])\n",
    "        y_try = np.array( [y_test[i]])\n",
    "\n",
    "        n=( evaluatecustom(X_try, y_try) )\n",
    "        #print(n)\n",
    "        if(n<0):\n",
    "            print('i',i)\n",
    "            print(X_test.shape,type(X_test))\n",
    "            print(X_try.shape)\n",
    "\n",
    "            print(y_test[i])\n",
    "            print(n)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(X_try.squeeze())\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
